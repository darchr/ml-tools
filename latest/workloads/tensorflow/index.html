<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tensorflow Models · ML-Tools</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>ML-Tools</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><a class="toctext" href="../../manifest/">Manifest</a></li><li><a class="toctext" href="../../notebooks/">Notebooks</a></li><li><span class="toctext">Docker</span><ul><li><a class="toctext" href="../../docker/docker/">Docker</a></li><li><a class="toctext" href="../../docker/tensorflow/">Tensorflow CPU</a></li></ul></li><li><span class="toctext">Datasets</span><ul><li><a class="toctext" href="../../datasets/imagenet/">Imagenet</a></li></ul></li><li><span class="toctext">Workloads</span><ul><li><a class="toctext" href="../ubuntu/">Ubuntu Workloads</a></li><li class="current"><a class="toctext" href>Tensorflow Models</a><ul class="internal"><li><a class="toctext" href="#Resnet-1">Resnet</a></li></ul></li><li><a class="toctext" href="../slim/">Slim</a></li><li><a class="toctext" href="../keras/">Keras Models</a></li></ul></li><li><span class="toctext">Launcher</span><ul><li><a class="toctext" href="../../launcher/">Launcher</a></li></ul></li><li><span class="toctext">NVM</span><ul><li><a class="toctext" href="../../nvm/swap/">Swap</a></li></ul></li><li><span class="toctext">Misc</span><ul><li><a class="toctext" href="../../extra/perf/">PAPI Notes</a></li></ul></li><li><a class="toctext" href="../../deprecated/">Deprecated Workloads</a></li></ul></nav><article id="docs"><header><nav><ul><li>Workloads</li><li><a href>Tensorflow Models</a></li></ul><a class="edit-page" href="https://github.com/darchr/ml-tools/blob/master/docs/src/workloads/tensorflow.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Tensorflow Models</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Tensorflow-Models-1" href="#Tensorflow-Models-1">Tensorflow Models</a></h1><h2><a class="nav-anchor" id="Resnet-1" href="#Resnet-1">Resnet</a></h2><p>A model for ResNet that can be trained on either Cifar or ImageNet, though as of now only ImageNet is supported.</p><ul><li><p>File: <code>/workloads/tensorflow/official/resnet/imagenet_main.py</code></p></li><li><p>Container entry point: <code>/models/official/resnet/imagenet_main.py</code></p></li><li><p>Dataset: </p></li><li><p>Volume Binds:</p></li><li><p><strong>Script Arguments</strong></p></li></ul><p>Common flags:     * <code>--batch_size=size</code> : Configure batch size. Default: <code>32</code>     * <code>--resnet_size=size</code> : Define the version of ResNet to use. Choices:          <code>18, 34, 50, 101, 152, 200</code>. Default: <code>50</code>     * <code>--train_epochs=N</code> : Number of epochs to train for. Default: <code>90</code>     * <code>--data_dir=path</code> : Path (inside the container) to the data directory. Default          provided by Launcher.  <strong>NOTE</strong>: If this is set to something besides <code>/imagenet</code> -          things will probably break horribly.</p><p>All flags:</p><pre><code class="language-sh">Runs a ResNet model on the ImageNet dataset.
flags:

absl.app:
  -?,--[no]help: show this help
    (default: &#39;false&#39;)
  --[no]helpfull: show full help
    (default: &#39;false&#39;)
  -h,--[no]helpshort: show this help
    (default: &#39;false&#39;)
  --[no]helpxml: like --helpfull, but generates XML output
    (default: &#39;false&#39;)
  --[no]only_check_args: Set to true to validate args and exit.
    (default: &#39;false&#39;)
  --[no]pdb_post_mortem: Set to true to handle uncaught exceptions with PDB post mortem.
    (default: &#39;false&#39;)
  --profile_file: Dump profile information to a file (for python -m pstats). Implies --run_with_profiling.
  --[no]run_with_pdb: Set to true for PDB debug mode
    (default: &#39;false&#39;)
  --[no]run_with_profiling: Set to true for profiling the script. Execution will be slower, and the output format might change over time.
    (default: &#39;false&#39;)
  --[no]use_cprofile_for_profiling: Use cProfile instead of the profile module for profiling. This has no effect unless --run_with_profiling is set.
    (default: &#39;true&#39;)

absl.logging:
  --[no]alsologtostderr: also log to stderr?
    (default: &#39;false&#39;)
  --log_dir: directory to write logfiles into
    (default: &#39;&#39;)
  --[no]logtostderr: Should only log to stderr?
    (default: &#39;false&#39;)
  --[no]showprefixforinfo: If False, do not prepend prefix to info messages when it&#39;s logged to stderr, --verbosity is set to INFO level, and python logging is used.
    (default: &#39;true&#39;)
  --stderrthreshold: log messages at this level, or more severe, to stderr in addition to the logfile.  Possible values are &#39;debug&#39;, &#39;info&#39;, &#39;warning&#39;, &#39;error&#39;, and &#39;fatal&#39;.
    Obsoletes --alsologtostderr. Using --alsologtostderr cancels the effect of this flag. Please also note that this flag is subject to --verbosity and requires logfile not
    be stderr.
    (default: &#39;fatal&#39;)
  -v,--verbosity: Logging verbosity level. Messages logged at this level or lower will be included. Set to 1 for debug logging. If the flag was not set or supplied, the
    value will be changed from the default of -1 (warning) to 0 (info) after flags are parsed.
    (default: &#39;-1&#39;)
    (an integer)

official.resnet.resnet_run_loop:
  --[no]eval_only:
    Skip training and only perform evaluation on the latest checkpoint.
    (default: &#39;false&#39;)
  -ft,--[no]fine_tune:
    If True do not train any parameters except for the final layer.
    (default: &#39;false&#39;)
  --[no]image_bytes_as_serving_input:
    If True exports savedmodel with serving signature that accepts JPEG image bytes
    instead of a fixed size [HxWxC] tensor that represents the image. The former is
    easier to use for serving at the expense of image resize/cropping being done as
    part of model inference. Note, this flag only applies to ImageNet and cannot be
    used for CIFAR.
    (default: &#39;false&#39;)
  -pmcp,--pretrained_model_checkpoint_path:
    If not None initialize all the network except the final layer with these values
  -rs,--resnet_size: &lt;18|34|50|101|152|200&gt;:
    The size of the ResNet model to use.
    (default: &#39;50&#39;)
  -rv,--resnet_version: &lt;1|2&gt;:
    Version of ResNet. (1 or 2) See README.md for details.
    (default: &#39;1&#39;)

official.utils.flags._base:
  -bs,--batch_size:
    Batch size for training and evaluation. When using multiple gpus, this is the
    global batch size for all devices. For example, if the batch size is 32 and
    there are 4 GPUs, each GPU will get 8 examples on each step.
    (default: &#39;32&#39;)
    (an integer)
  --[no]clean:
    If set, model_dir will be removed if it exists.
    (default: &#39;false&#39;)
  -dd,--data_dir:
    The location of the input data.
    (default: &#39;/tmp&#39;)
  -ebe,--epochs_between_evals:
    The number of training epochs to run between evaluations.
    (default: &#39;1&#39;)
    (an integer)
  -ed,--export_dir:
    If set, a SavedModel serialization of the model will be exported to this
    directory at the end of training. See the README for more details and relevant
    links.
  -hk,--hooks:
    A list of (case insensitive) strings to specify the names of training hooks.
      Hook:
        loggingtensorhook
        loggingmetrichook
        examplespersecondhook
        profilerhook
      Example: `--hooks ProfilerHook,ExamplesPerSecondHook`
    See official.utils.logs.hooks_helper for details.
    (default: &#39;LoggingTensorHook&#39;)
    (a comma separated list)
  -md,--model_dir:
    The location of the model checkpoint files.
    (default: &#39;/tmp&#39;)
  -ng,--num_gpus:
    How many GPUs to use with the DistributionStrategies API. The default is 1 if
    TensorFlow can detect a GPU, and 0 otherwise.
    (default: &#39;0&#39;)
    (an integer)
  -st,--stop_threshold:
    If passed, training will stop at the earlier of train_epochs and when the
    evaluation metric is  greater than or equal to stop_threshold.
    (a number)
  -te,--train_epochs:
    The number of epochs used to train.
    (default: &#39;90&#39;)
    (an integer)

official.utils.flags._benchmark:
  -bld,--benchmark_log_dir:
    The location of the benchmark logging.
  --benchmark_logger_type: &lt;BaseBenchmarkLogger|BenchmarkFileLogger|BenchmarkBigQueryLogger&gt;:
    The type of benchmark logger to use. Defaults to using BaseBenchmarkLogger
    which logs to STDOUT. Different loggers will require other flags to be able to
    work.
    (default: &#39;BaseBenchmarkLogger&#39;)
  -bti,--benchmark_test_id:
    The unique test ID of the benchmark run. It could be the combination of key
    parameters. It is hardware independent and could be used compare the performance
    between different test runs. This flag is designed for human consumption, and
    does not have any impact within the system.
  -bds,--bigquery_data_set:
    The Bigquery dataset name where the benchmark will be uploaded.
    (default: &#39;test_benchmark&#39;)
  -bmt,--bigquery_metric_table:
    The Bigquery table name where the benchmark metric information will be
    uploaded.
    (default: &#39;benchmark_metric&#39;)
  -brst,--bigquery_run_status_table:
    The Bigquery table name where the benchmark run status information will be
    uploaded.
    (default: &#39;benchmark_run_status&#39;)
  -brt,--bigquery_run_table:
    The Bigquery table name where the benchmark run information will be uploaded.
    (default: &#39;benchmark_run&#39;)
  -gp,--gcp_project:
    The GCP project name where the benchmark will be uploaded.

official.utils.flags._misc:
  -df,--data_format: &lt;channels_first|channels_last&gt;:
    A flag to override the data format used in the model. channels_first provides a
    performance boost on GPU but is not always compatible with CPU. If left
    unspecified, the data format will be chosen automatically based on whether
    TensorFlow was built for CPU or GPU.

official.utils.flags._performance:
  -ara,--all_reduce_alg:
    Defines the algorithm to use for performing all-reduce.See
    tf.contrib.distribute.AllReduceCrossTowerOps for more details and available
    options.
  --datasets_num_parallel_batches:
    Determines how many batches to process in parallel when using map and batch
    from tf.data.
    (an integer)
  --datasets_num_private_threads:
    Number of threads for a private threadpool created for alldatasets
    computation..
    (an integer)
  -dt,--dtype: &lt;fp16|fp32&gt;:
    The TensorFlow datatype used for calculations. Variables may be cast to a
    higher precision on a case-by-case basis for numerical stability.
    (default: &#39;fp32&#39;)
  -inter,--inter_op_parallelism_threads:
    Number of inter_op_parallelism_threads to use for CPU. See TensorFlow
    config.proto for details.
    (default: &#39;0&#39;)
    (an integer)
  -intra,--intra_op_parallelism_threads:
    Number of intra_op_parallelism_threads to use for CPU. See TensorFlow
    config.proto for details.
    (default: &#39;0&#39;)
    (an integer)
  -ls,--loss_scale:
    The amount to scale the loss by when the model is run. Before gradients are
    computed, the loss is multiplied by the loss scale, making all gradients
    loss_scale times larger. To adjust for this, gradients are divided by the loss
    scale before being applied to variables. This is mathematically equivalent to
    training without a loss scale, but the loss scale helps avoid some intermediate
    gradients from underflowing to zero. If not provided the default for fp16 is 128
    and 1 for all other dtypes.
    (an integer)
  -mts,--max_train_steps:
    The model will stop training if the global_step reaches this value. If not set,
    training will run until the specified number of epochs have run as usual. It is
    generally recommended to set --train_epochs=1 when using this flag.
    (an integer)
  -gt_mode,--tf_gpu_thread_mode:
    Whether and how the GPU device uses its own threadpool.
  -synth,--[no]use_synthetic_data:
    If set, use fake data (zeroes) instead of a real dataset. This mode is useful
    for performance debugging, as it removes input processing steps, but will not
    learn anything.
    (default: &#39;false&#39;)

absl.flags:
  --flagfile: Insert flag definitions from the given file into the command line.
    (default: &#39;&#39;)
  --undefok: comma-separated list of flag names that it is okay to specify on the command line even if the program does not define a flag with that name.  IMPORTANT: flags
    in this list that have arguments MUST use the --flag=value format.
    (default: &#39;&#39;)</code></pre><p><strong>Launcher Docs</strong></p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Launcher.ResnetTF" href="#Launcher.ResnetTF"><code>Launcher.ResnetTF</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Struct representing parameters for launching the Tensorflow Official Resnet Model on the Imagenet training set. Construct type using a key-word constructor</p><p><strong>Fields</strong></p><ul><li><p><code>args::NamedTuple</code> - Arguments passed to the Keras Python script that creates and   trains Resnet.</p></li><li><p><code>interactive::Bool</code> - Set to <code>true</code> to create a container that does not automatically run   Resnet when launched. Useful for debugging what&#39;s going on inside the container.</p></li></ul><p><strong><a href="../../launcher/#Launcher.create"><code>create</code></a> keywords</strong></p><ul><li><p><code>small_dataset::Bool</code> - If <code>true</code>, use <code>imagenet_tf_official_small</code> as the training   dataset, which is essentially just a subset of the full Imagenet. Otherwise, use   <code>imagenet_tf_official</code>. Default: <code>false</code>.</p></li><li><p><code>memory::Union{Nothing, Int}</code> - The amount of memory to assign to this container. If   this value is <code>nothing</code>, the container will have access to all system memory.   Default: <code>nothing</code>.</p></li><li><p><code>cpuSets = &quot;&quot;</code> - The CPU sets on which to run the workload. Defaults to all processors.   Examples: <code>&quot;0&quot;</code>, <code>&quot;0-3&quot;</code>, <code>&quot;1,3&quot;</code>.</p></li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaLang/julia/blob/099e826241fca365a120df9bac9a9fede6e7bae4/base/#L0-L24">source</a></section><p><strong><code>imagenet_main.py</code></strong></p><ul><li><p>Lines 42-47: Made script expect training and validation files to be in <code>train</code> and    <code>validation</code> directories respectively whereas the original expected both to be in   the same directory.</p><p>Aditionally, made the <code>_NUM_TRAIN_FILES</code> and <code>_NUM_VALIDATION_FILES</code> be assigned to   the number of files in these directories.</p><p>This allows us to operate on a subset of the ImageNet data by just pointing to another   folder.</p><p>Also hardcoded <code>_DATA_DIR</code> to <code>/imagenet</code> to allow this to take place. This limits the   migratability of this project outside of docker, but we&#39;ll deal with that when we need   to.</p></li></ul><p>**<code>utils/logs/hooks.py</code></p><ul><li>Line 75: Change default value for <code>every_n_iter</code> from 100 to 5, allowing for finer    resolution benchmarking.</li></ul><footer><hr/><a class="previous" href="../ubuntu/"><span class="direction">Previous</span><span class="title">Ubuntu Workloads</span></a><a class="next" href="../slim/"><span class="direction">Next</span><span class="title">Slim</span></a></footer></article></body></html>
