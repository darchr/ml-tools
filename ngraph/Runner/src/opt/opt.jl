#####
##### Initial Setup
#####

# For just the initial formulation, we need the following pipeline:
#
# - Base data structure will be a vector of nGraph ops in `ordered_ops` structure,
#   which is the order that they are executed by the nGraph runtime.
#
# - Get a list of all intermediate tensors and sizes.
#   Each tensor can either live in DRAM or PMEM, so we need to generate JuMP variables
#   accordingly.
#
# - Do a liveness analysis to determine where tensors begin and when they go out of
#   scope.
#
# - Iterate through each op in the nGraph ops. For each op, generate
#
#   1. A capacity constraint on the number of live tensors in DRAM.
#   2. Generate a `gadget` to encode the running time of the kernel given the locations
#      of its inputs and outputs.
#   3. Add the results of this gadget to the global objective function, which will be
#      to minimize the sum of active running times.
#
# To accomplish this, we need to pass around a JuMP `Model` which we may progressively
# add variables and constraints to.
#
# To sequentially build the objective function, we can have a JuMP `expression`
# (http://www.juliaopt.org/JuMP.jl/v0.19.0/expressions/) which we update with the
# `add_to_expression!` function at each node in the graph.

# Struct to be passed around since all these items are generally used together anyways.
mutable struct Frame{T}
    modeltype::T
    model::JuMP.Model
    profile_data::ProfileData
end

limit(F::Frame) = limit(F.modeltype)

JuMP.optimize!(F::Frame) = optimize!(F.model)

include("affinity.jl")
include("ilp.jl")
include("inspect.jl")
include("configure.jl")
include("modnn/modnn.jl")
include("numa/numa.jl")

function actualize(backend, func; env = (), nkw...)
    f, args, kw = func()
    return withenv(env...) do
        nGraph.compile(backend, f, args...; kw..., nkw...)
    end
end

# Default is to fallback to the inner call
factory(args...; kw...) = _factory(args...; kw...)

# Ratio optimizers go through a refinement step
function factory(
        backend::nGraph.Backend{nGraph.CPU}, 
        func, 
        opt::AbstractOptimizer{Rational{Int64}}; 
        kw...
    )
    return ratiosearch(_factory, func, opt; kw...)
end

function ratiosearch(f, backend, func, opt; search_ratio = true, refinements = 7, kw...)
    @info "Trying Ratio $(getratio(opt))"

    # Just return the inner factory if we aren't interesting in performing a binary search
    # for the actual ratio to input that will return the desired ratio
    search_ratio || return f(backend, func, opt; kw...)

    # Perform a binary search
    ret = f(backend, func, opt; kw...)
    fex = first(ret)
    args = Base.tail(ret)

    # If we're within the desired tolerance, just return like normal
    checkmargin(fex, opt) && return (fex, args...)

    # For now, I'm assuming that the ratio generated by the optimized graph will always
    # be greater than the desired ratio due to defragmentation.
    @assert getratio(fex) > getratio(opt)

    # Start doing a grid search
    #
    # The function desired_ratio -> actual_ratio is not necessarily monotonic, so we can't
    # use a binary search. Instead this grid search thing seems to work alright.
    best_ratio = getratio(opt)
    best_err = geterr(fex, opt)
    current_ratio = best_ratio

    best_fex = fex
    best_args = args

    for i in 1:refinements
        # Use a step size starting with 1 and increasing or decreasing by the step size
        # until the ratio crosses the boundary of what we want.
        step = 1 // (2 ^ (i - 1))
        @info """
        ------------------------
        Performing Refinement Iteration $i
        Step: $step
        ------------------------
        """

        for _ in 1:2
            current_ratio -= step
            current_ratio < 0 && break

            @info "Trying Ratio: $(convert(Float64, current_ratio))"
            ret = f(backend, func, _optimizer(opt, current_ratio); kw...)
            fex = first(ret)
            args = Base.tail(ret)

            @show typeof(fex)
            @show typeof(args)

            # If the ratios switch sign, time to exit
            getratio(fex) <= getratio(opt) && break

            current_err = geterr(fex, opt)
            @info """
            Current Ratio: $(convert(Float64, current_ratio))
            Best Ratio: $(convert(Float64, best_ratio))

            Current Error: $(convert(Float64, current_err))
            Best Error: $(convert(Float64, best_err))
            """
            if current_err < best_err
                best_ratio = current_ratio
                best_err = current_err
                best_fex = fex
                best_args = args
            end
        end
        current_ratio = best_ratio
    end

    return (best_fex, best_args...)
end

function _factory(
        backend::nGraph.Backend,
        func,
        opt::T;
        # Useful for the GPU case
        adjust_io = false,
        defrag = true,
        profile_kw...
    ) where {T <: AbstractOptimizer}

    # Get the function, arguments, and keyword arguments from the provided function
    f, args, kw = func()

    # add a callback that will populate a reference to a `ProfileData` type
    frame_ref = Ref{Frame}()
    limits_ref = Ref{Vector{Int}}()
    creation_times = Float64[]
    optimization_times = Float64[]

    #A callback that profiles the ngraph function
    function cb(f::nGraph.NFunction)
        # Do some minor editing the order of nodes in the graph to hopefully yield slightly
        # better memory characteristics
        priority_pass!(f)
        data = profile(f, backend; profile_kw...)

        # Initialize the node dram limits if needed
        if !isdefined(limits_ref, :x)
            # Get the limit from the optimizer
            # Find the input and output size of the function and subtract that from the
            # limit along with a fudge factor so we can fit the model on the GPU
            if adjust_io
                io_size = sum(sizeof, input_tensors(f)) + sum(sizeof, output_tensors(f))
                limit = max(getlimit(opt) - io_size, 0)
                opt_adjusted = _optimizer(opt, limit)
                modeltype = opt_adjusted(data, backend)
            else
                modeltype = opt(data, backend)
            end

            # Save the limits to the reference for reuse across defragmentation.
            limits_ref[] = modeltype.dram_limits
        else
            modeltype = opt(data, backend)
            modeltype.dram_limits = limits_ref[]
        end

        # Record statistics about how long solving takes.
        creation_time = @elapsed(frame = create_model(modeltype, data))
        optimization_time = @elapsed(optimize!(frame))

        push!(creation_times, creation_time)
        push!(optimization_times, optimization_time)

        tensor_map = configure!(f, frame)
        frame_ref[] = frame
        return nothing
    end

    # Defrag callback - if a function needs defragging, throws a `CompilerExit` exception to
    # avoid nGraph trying to allocate too much GPU memory
    function defrag_cb(f::nGraph.NFunction)
        if exceeds_limit(f, frame_ref[].modeltype)
            # This is pretty ugly - sorry about that.
            modeltype = update(frame_ref[].modeltype, profile(f, backend))
            limits_ref[] = modeltype.dram_limits

            throw(CompilerExit())
        end
    end

    # Compile the function to a ngraph executable
    local fex
    retry = true
    while retry
        retry = false

        # Setup callbacks
        #
        # If the function needs defragging, a `CompilerExit` exception will be thrown and we
        # will have to try again.
        callbacks = CallbackChain()
        callback!(callbacks, cb)
        defrag && callback!(callbacks, defrag_cb)

        try
            fex = nGraph.compile(
                backend,
                f,
                args...;
                callback = callbacks,
                emit_timing = true,
                kw...
            )
        catch e
            isa(e, CompilerExit) || rethrow(e)
            retry = true
        end
    end

    metadata = Dict(
        :creation_times => creation_times,
        :optimization_times => optimization_times,
    )

    return fex, frame_ref[], metadata
end

